{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the modules\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from sklearn.metrics import balanced_accuracy_score, confusion_matrix, classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split the Data into Training and Testing Sets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Read the `lending_data.csv` data from the `Resources` folder into a Pandas DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loan_size</th>\n",
       "      <th>interest_rate</th>\n",
       "      <th>borrower_income</th>\n",
       "      <th>debt_to_income</th>\n",
       "      <th>num_of_accounts</th>\n",
       "      <th>derogatory_marks</th>\n",
       "      <th>total_debt</th>\n",
       "      <th>loan_status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>59921</th>\n",
       "      <td>10500.0</td>\n",
       "      <td>7.607</td>\n",
       "      <td>52200</td>\n",
       "      <td>0.425287</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>22200</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8483</th>\n",
       "      <td>9600.0</td>\n",
       "      <td>7.190</td>\n",
       "      <td>48300</td>\n",
       "      <td>0.378882</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>18300</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49892</th>\n",
       "      <td>8600.0</td>\n",
       "      <td>6.788</td>\n",
       "      <td>44500</td>\n",
       "      <td>0.325843</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>14500</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9629</th>\n",
       "      <td>7400.0</td>\n",
       "      <td>6.278</td>\n",
       "      <td>39700</td>\n",
       "      <td>0.244332</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>9700</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10980</th>\n",
       "      <td>9800.0</td>\n",
       "      <td>7.300</td>\n",
       "      <td>49300</td>\n",
       "      <td>0.391481</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>19300</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56634</th>\n",
       "      <td>10000.0</td>\n",
       "      <td>7.372</td>\n",
       "      <td>50000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>20000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76560</th>\n",
       "      <td>16100.0</td>\n",
       "      <td>9.971</td>\n",
       "      <td>74400</td>\n",
       "      <td>0.596774</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>44400</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40563</th>\n",
       "      <td>9800.0</td>\n",
       "      <td>7.270</td>\n",
       "      <td>49000</td>\n",
       "      <td>0.387755</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>19000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37767</th>\n",
       "      <td>9500.0</td>\n",
       "      <td>7.161</td>\n",
       "      <td>48000</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>18000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24238</th>\n",
       "      <td>8600.0</td>\n",
       "      <td>6.798</td>\n",
       "      <td>44600</td>\n",
       "      <td>0.327354</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>14600</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       loan_size  interest_rate  borrower_income  debt_to_income  \\\n",
       "59921    10500.0          7.607            52200        0.425287   \n",
       "8483      9600.0          7.190            48300        0.378882   \n",
       "49892     8600.0          6.788            44500        0.325843   \n",
       "9629      7400.0          6.278            39700        0.244332   \n",
       "10980     9800.0          7.300            49300        0.391481   \n",
       "56634    10000.0          7.372            50000        0.400000   \n",
       "76560    16100.0          9.971            74400        0.596774   \n",
       "40563     9800.0          7.270            49000        0.387755   \n",
       "37767     9500.0          7.161            48000        0.375000   \n",
       "24238     8600.0          6.798            44600        0.327354   \n",
       "\n",
       "       num_of_accounts  derogatory_marks  total_debt  loan_status  \n",
       "59921                4                 1       22200            0  \n",
       "8483                 4                 0       18300            0  \n",
       "49892                3                 0       14500            0  \n",
       "9629                 2                 0        9700            0  \n",
       "10980                4                 0       19300            0  \n",
       "56634                4                 0       20000            0  \n",
       "76560                9                 2       44400            1  \n",
       "40563                4                 0       19000            0  \n",
       "37767                4                 0       18000            0  \n",
       "24238                3                 0       14600            0  "
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read the CSV file from the Resources folder into a Pandas DataFrame\n",
    "df_lending = pd.read_csv(\"lending_data.csv\")\n",
    "# Review the DataFrame\n",
    "df_lending.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['loan_size', 'interest_rate', 'borrower_income', 'debt_to_income',\n",
       "       'num_of_accounts', 'derogatory_marks', 'total_debt', 'loan_status'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_lending.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Create the labels set (`y`)  from the “loan_status” column, and then create the features (`X`) DataFrame from the remaining columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate the data into labels and features\n",
    "\n",
    "# Separate the X variable, the features\n",
    "X = df_lending.copy()\n",
    "X.drop(\"loan_status\", axis=1, inplace=True)\n",
    "\n",
    "# Separate the y variable, the labels\n",
    "y = df_lending[\"loan_status\"].values.reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0]], dtype=int64)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Review the y variable Series\n",
    "y[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loan_size</th>\n",
       "      <th>interest_rate</th>\n",
       "      <th>borrower_income</th>\n",
       "      <th>debt_to_income</th>\n",
       "      <th>num_of_accounts</th>\n",
       "      <th>derogatory_marks</th>\n",
       "      <th>total_debt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10700.0</td>\n",
       "      <td>7.672</td>\n",
       "      <td>52800</td>\n",
       "      <td>0.431818</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>22800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8400.0</td>\n",
       "      <td>6.692</td>\n",
       "      <td>43600</td>\n",
       "      <td>0.311927</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>13600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9000.0</td>\n",
       "      <td>6.963</td>\n",
       "      <td>46100</td>\n",
       "      <td>0.349241</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>16100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10700.0</td>\n",
       "      <td>7.664</td>\n",
       "      <td>52700</td>\n",
       "      <td>0.430740</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>22700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10800.0</td>\n",
       "      <td>7.698</td>\n",
       "      <td>53000</td>\n",
       "      <td>0.433962</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>23000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   loan_size  interest_rate  borrower_income  debt_to_income  num_of_accounts  \\\n",
       "0    10700.0          7.672            52800        0.431818                5   \n",
       "1     8400.0          6.692            43600        0.311927                3   \n",
       "2     9000.0          6.963            46100        0.349241                3   \n",
       "3    10700.0          7.664            52700        0.430740                5   \n",
       "4    10800.0          7.698            53000        0.433962                5   \n",
       "\n",
       "   derogatory_marks  total_debt  \n",
       "0                 1       22800  \n",
       "1                 0       13600  \n",
       "2                 0       16100  \n",
       "3                 1       22700  \n",
       "4                 1       23000  "
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Review the X variable DataFrame\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Check the balance of the labels variable (`y`) by using the `value_counts` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    75036\n",
      "1     2500\n",
      "Name: loan_status, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Check the balance of our target values\n",
    "loan_status_count = df_lending['loan_status'].value_counts()\n",
    "print(loan_status_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Split the data into training and testing datasets by using `train_test_split`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the train_test_learn module\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split the data using train_test_splite\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the StandardScaler instance to scale the data. Although not part of the directions, it is part of the standard analytical process \n",
    "scaler = StandardScaler()\n",
    "X_scaler = scaler.fit(X_train)\n",
    "X_train_scaled = X_scaler.transform(X_train)\n",
    "X_test_scaled = X_scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a Logistic Regression Model with the Original Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Step 1: Fit a logistic regression model by using the training data (`X_train` and `y_train`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\krist\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "# Import the LogisticRegression module from SKLearn\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Instantiate the Logistic Regression model\n",
    "# Assign a random_state parameter of 1 to the model\n",
    "logistic_regression_model = LogisticRegression(random_state=1)\n",
    "\n",
    "# Fit the model using training data\n",
    "lr_model = logistic_regression_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Save the predictions on the testing data labels by using the testing feature data (`X_test`) and the fitted model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=int64)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make a prediction using the testing data\n",
    "testing_predictions = lr_model.predict(X_test)\n",
    "testing_predictions[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Evaluate the model’s performance by doing the following:\n",
    "\n",
    "* Calculate the accuracy score of the model.\n",
    "\n",
    "* Generate a confusion matrix.\n",
    "\n",
    "* Print the classification report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9520479254722232\n"
     ]
    }
   ],
   "source": [
    "# Print the balanced_accuracy score of the model\n",
    "accuracy = balanced_accuracy_score(y_test, testing_predictions)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[18663   102]\n",
      " [   56   563]]\n"
     ]
    }
   ],
   "source": [
    "# Generate a confusion matrix for the model\n",
    "test_matrix = confusion_matrix(y_test, testing_predictions)\n",
    "print(test_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      1.00     18765\n",
      "           1       0.85      0.91      0.88       619\n",
      "\n",
      "    accuracy                           0.99     19384\n",
      "   macro avg       0.92      0.95      0.94     19384\n",
      "weighted avg       0.99      0.99      0.99     19384\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print the TESTING classification report for the model\n",
    "testing_report = classification_report(y_test, testing_predictions)\n",
    "\n",
    "# Print the testing classification report\n",
    "print(testing_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[55994   277]\n",
      " [  181  1700]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     56271\n",
      "           1       0.86      0.90      0.88      1881\n",
      "\n",
      "    accuracy                           0.99     58152\n",
      "   macro avg       0.93      0.95      0.94     58152\n",
      "weighted avg       0.99      0.99      0.99     58152\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create and save the confusion matrix for the training data\n",
    "training_predictions = lr_model.predict(X_train)\n",
    "training_matrix = confusion_matrix(y_train, training_predictions)\n",
    "\n",
    "# Print the confusion matrix for the training data\n",
    "print(training_matrix)\n",
    "\n",
    "# Print the TRAINING classification report for the model\n",
    "training_report = classification_report(y_train, training_predictions)\n",
    "print(training_report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Answer the following question."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question:** How well does the logistic regression model predict both the `0` (healthy loan) and `1` (high-risk loan) labels?\n",
    "\n",
    "**Answer:** \n",
    "\n",
    "Overall, the model shows excellent performance in predicting healthy loans (class \"0\") with very high precision, recall, and F1-score. It also performs well in identifying high-risk loans (class \"1\") with good precision, recall, and F1-score, although not as high as for the healthy loans. The accuracy of the model is 0.99, indicating that it correctly predicts the labels for 99% of the loans in the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict a Logistic Regression Model with Resampled Training Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Use the `RandomOverSampler` module from the imbalanced-learn library to resample the data. Be sure to confirm that the labels have an equal number of data points. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the RandomOverSampler module form imbalanced-learn\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "\n",
    "# Instantiate the random oversampler model\n",
    "# Assign a random_state parameter of 1 to the model\n",
    "random_state_model = RandomOverSampler(random_state=1)\n",
    "\n",
    "# Fit the original training data to the random_oversampler model\n",
    "ro_model = random_state_model.fit_resample(X_train, y_train)\n",
    "\n",
    "X_train_rs = ro_model[0]\n",
    "y_train_rs = ro_model[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of distinct values in X_train: 5980\n",
      "Number of distinct values in y_train: 2\n"
     ]
    }
   ],
   "source": [
    "# Count the distinct values of the resampled features data\n",
    "distinct_values_X = np.unique(X_train)\n",
    "count_X = len(distinct_values_X)\n",
    "print(\"Number of distinct values in X_train:\", count_X)\n",
    "\n",
    "# Count the distinct values of the resampled labels data\n",
    "distinct_values_y = np.unique(y_train)\n",
    "count_y = len(distinct_values_y)\n",
    "print(\"Number of distinct values in y_train:\", count_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Use the `LogisticRegression` classifier and the resampled data to fit the model and make predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the Logistic Regression model\n",
    "# Assign a random_state parameter of 1 to the model\n",
    "logistic_regression_model_rs = LogisticRegression(random_state=1)\n",
    "\n",
    "# Fit the model using the resampled training data\n",
    "lr_model_rs = logistic_regression_model_rs.fit(X_train_rs, y_train_rs)\n",
    "\n",
    "# Make a prediction using the testing data\n",
    "testing_predictions_rs = lr_model_rs.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Evaluate the model’s performance by doing the following:\n",
    "\n",
    "* Calculate the accuracy score of the model.\n",
    "\n",
    "* Generate a confusion matrix.\n",
    "\n",
    "* Print the classification report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9936781215845847\n"
     ]
    }
   ],
   "source": [
    "# Print the balanced_accuracy score of the model \n",
    "accuracy_rs = balanced_accuracy_score(y_test, testing_predictions_rs)\n",
    "print(accuracy_rs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[18649   116]\n",
      " [    4   615]]\n"
     ]
    }
   ],
   "source": [
    "# Generate a confusion matrix for the model\n",
    "testing_matrix_rs = confusion_matrix(y_test, testing_predictions_rs)\n",
    "print(testing_matrix_rs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      1.00     18765\n",
      "           1       0.84      0.99      0.91       619\n",
      "\n",
      "    accuracy                           0.99     19384\n",
      "   macro avg       0.92      0.99      0.95     19384\n",
      "weighted avg       0.99      0.99      0.99     19384\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print the classification report for the model\n",
    "testing_report_rs = classification_report(y_test, testing_predictions_rs)\n",
    "print(testing_report_rs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Answer the following question"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question:** How well does the logistic regression model, fit with oversampled data, predict both the `0` (healthy loan) and `1` (high-risk loan) labels?\n",
    "\n",
    "**Answer:** Similiar to the first analysis, and based on the classification report and the confusion matrix, the model shows excellent performance in predicting healthy loans (class \"0\") with very high precision, recall, and F1-score. It also performs well in identifying high-risk loans (class \"1\") with good precision, recall, and F1-score, although not as high as for the healthy loans. The overall accuracy of the model is also quite high, indicating its effectiveness in making accurate predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The purpose of the analysis was to develop machine learning models to predict the loan status based on various financial information provided in the dataset. The data consisted of loan size, interest rate, borrower income, debt to income ration, the number of accounts, any derogatory marks on the account, the total debt, and finally, the loan status.\n",
    "\n",
    "The goal of the analysis was to predict the loan status, which in our dataset, is a binary variable indicating whether a loan is classified as a \"0\" (healthy loan) or a \"1\" (high risk loan).\n",
    "\n",
    "To understand the distribution of the loan status variable, we used the value_counts function. This provided a count of the different loan statuses in the dataset. The analysis found that there were 18,765 healthy loans (class \"0\") and 619 high-risk loans (class \"1\"). This is not a very balanced dataset, as ideally we would see a far greater number of high-risk loans.\n",
    "\n",
    "The stages of the machine learning process involved the following steps:\n",
    "\n",
    "Data Preparation: The dataset was loaded into a Pandas DataFrame. The features (independent variables) were separated into the variable X, while the target variable (loan_status) was separated into the variable y.\n",
    "\n",
    "Exploratory Data Analysis: Basic exploratory analysis was performed to gain insights into the dataset, such as reviewing the DataFrame, checking the balance of the loan_status labels using value_counts, and examining the distribution of the variables.\n",
    "\n",
    "Model Training: The dataset was split into training and testing sets using the train_test_split function. Logistic regression models were trained on the training data using the LogisticRegression class from SKLearn.\n",
    "\n",
    "Model Evaluation: The trained models were used to make predictions on the testing data. The performance of the models was evaluated using metrics such as balanced accuracy score, confusion matrix, and classification report. These metrics provided insights into the models' accuracy, precision, recall, and F1-score for both the \"0\" and \"1\" classes.\n",
    "\n",
    "Resampling: In the subsequent analysis, resampling techniques were applied to address the class imbalance in the dataset. The RandomOverSampler from the imbalanced-learn library was used to oversample the minority class (\"1\" class) to achieve a more balanced dataset.\n",
    "\n",
    "Model Training and Evaluation with Resampled Data: The logistic regression model was trained on the resampled training data, and predictions were made on the testing data. The performance of the model was evaluated using metrics such as balanced accuracy score, confusion matrix, and classification report.\n",
    "\n",
    "The main method used in this analysis was logistic regression (LogisticRegression) for binary classification. Additionally, the RandomOverSampler from the imbalanced-learn library was used to address the class imbalance issue by oversampling the minority class.\n",
    "\n",
    "Overall, the analysis involved data preparation, model training, evaluation, and optional resampling to develop a predictive model for loan status classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Machine Learning Module 1:**\n",
    "\n",
    "With the metrics from our classification reports, **precision** focuses on the accuracy of positive predictions, **recall** focuses on the ability to find all positive instances, and **F1-score** combines both metrics to give an overall evaluation of the model's performance.\n",
    "\n",
    "For the \"0\" class (healthy loan):\n",
    "\n",
    "**Precision:** The model achieves a precision of 1.00, indicating that when it predicts a loan as healthy, it is correct 100% of the time.\\\n",
    "**Recall:** The model has a recall of 0.99, suggesting that it correctly identifies 99% of the actual healthy loans.\\\n",
    "**F1-score:** The F1-score, which combines precision and recall, is 1.00. This score indicates a very high overall performance for the \"0\" class.\n",
    "\n",
    "For the \"1\" class (high-risk loan):\n",
    "\n",
    "**Precision:** The precision for the high-risk loans is 0.85, indicating that when the model predicts a loan as high-ris|k, it is correct approximately 85% of the time.\\\n",
    "**Recall:** The recall is 0.91, implying that the model correctly identifies 91% of the actual high-risk loans.\\\n",
    "**F1-score:** The F1-score for the \"1\" class is 0.88, reflecting a reasonably good overall performance.\n",
    "\n",
    "**Accuracy:** The accuracy score of the model 0.952, which means it correctly predicts the labels for approximately 95.2% of the loans in the dataset.\n",
    "\n",
    "\n",
    "              Precision    Recall  F1-score   Support\n",
    "\n",
    "           0       1.00      0.99      1.00     18765\n",
    "           1       0.85      0.91      0.88       619\n",
    "\n",
    "    Accuracy                           0.99     19384\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Machine Learning Module 2:**\n",
    "\n",
    "For the \"0\" class (healthy loan):\n",
    "\n",
    "**Precision:** The precision is 1.00, indicating that when the model predicts a loan as healthy, it is correct 100% of the time.\\\n",
    "**Recall:** The recall is 0.99, suggesting that it correctly identifies 99% of the actual healthy loans.\\\n",
    "**F1-score:** The F1-score is 1.00, reflecting a very high overall performance for the \"0\" class\n",
    "\n",
    "For the \"1\" class (high-risk loan):\n",
    "\n",
    "**Precision:** The precision for the high-risk loans is 0.84, indicating that when the model predicts a loan as high-risk, it is correct approximately 85% of the time.\\\n",
    "**Recall:** The recall is 0.99, implying that the model correctly identifies 99% of the actual high-risk loans.\\\n",
    "**F1-score:** The F1-score for the \"1\" class is 0.91, reflecting a excellent overall performance.\n",
    "\n",
    "**Accuracy:** The accuracy score of the model is 0.994, which means it correctly predicts the labels for approximately 99.4% of the loans in the dataset.\n",
    "\n",
    "\n",
    "              Precision    Recall  F1-score   Support\n",
    "\n",
    "           0       1.00      0.99      1.00     18765\n",
    "           1       0.84      0.99      0.91       619\n",
    "\n",
    "    Accuracy                           0.99     19384\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the results, both the resampled model and original model show a high level of accuracy and demonstrate good performance in predicting both classes of loan risk. However, after completing an analysis from both models, the resampled model shows slightly higher accuracy (0.994) compared to the first model (0.952). Additionally, the resampled model achieves higher precision, recall, and F1-score for the minority class (\"1\" class), indicating a better ability to identify high-risk loans.\n",
    "\n",
    "When determining which model is the best, if the main objective is to achieve overall accuracy and balanced performance for both classes, the resampled model is recommended. It not only achieves high accuracy but also demonstrates improved precision, recall, and F1-score for the high-risk loans. This model would be suitable when both classes (\"0\" and \"1\") are equally important.\n",
    "\n",
    "Likewise, the resampled model more accurately identifies high-risk loans (\"1\" class), it performs better in terms of precision, recall, and F1-score for the minority class. This can be crucial in situations where correctly identifying high-risk loans is of paramount importance.Considering the slightly higher accuracy and improved performance for the minority class, the resampled model appears to be the preferred choice.\n",
    "\n",
    "Lastly, we should consider that rather than working with a robust dataset, we are relying on resampling to complete our analysis. We would likely have greater accuracy if we started with a more balanced dataset, and not relied on the resampling. Resampling can artificially balance the dataset, but it does not address the underlying class imbalance issue in the real world. The model's performance may not generalize well to unseen data from the same problem domain, where class imbalance persists. Finding a more balanced dataset from the start can help mitigate these limitations. \n",
    "\n",
    "It is important to carefully consider the trade-offs between resampling and obtaining a more balanced dataset. If possible, collecting or acquiring a balanced dataset in the first place is preferred. However, if obtaining a balanced dataset is not feasible, resampling techniques can be valuable tools to address class imbalance and improve model performance, while being mindful of their limitations."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
